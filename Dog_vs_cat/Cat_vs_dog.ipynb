{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione 4: classificazione cani e gatti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Memory\n",
    "from skimage import feature, color, transform\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import ml_utilities\n",
    "import ml_visualization\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento in corso ...\n",
      "Caricate 900 immagini in 0.18 s.\n",
      "Gatti: 509\n",
      "Cani: 391\n"
     ]
    }
   ],
   "source": [
    "db_path = 'DBs/CaniGatti_ML18'\n",
    "exp_path = 'Experiments'\n",
    "train_filelist = 'BinaryTrainingSet.txt'  \n",
    "\n",
    "# Predisposizione di un'area di caching su disco che velocizza la riesecuzione di chiamate di funzioni con gli stessi parametri\n",
    "memory = Memory(exp_path, verbose=0)  \n",
    "\n",
    "# Caricamento delle immagini\n",
    "print('Caricamento in corso ...')\n",
    "start = time.time()\n",
    "train_raw_x, train_y = ml_utilities.load_labeled_dataset(train_filelist, db_path, cache=memory)\n",
    "\n",
    "print('Caricate %d immagini in %.2f s.' % (len(train_raw_x), time.time() - start))\n",
    "print('Gatti:', np.count_nonzero(train_y == 0))\n",
    "print('Cani:', np.count_nonzero(train_y == 1))\n",
    "\n",
    "# Shuffle del training set\n",
    "ml_utilities.shuffle_in_unison([train_raw_x, train_y], seed=1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_side = 128\n",
    "train_raw_x = ml_utilities.resize_images(train_raw_x, image_side, image_side, cache=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrazione delle feature HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HogRider(orientation,side):\n",
    "     train_feature_x = ml_utilities.extract_hog(train_raw_x, \n",
    "                                           convert_to_gray=True, orientations=orientation,\n",
    "                                           pixels_per_cell=(side,side), cells_per_block=(1, 1),\n",
    "                                           cache=memory)\n",
    "     return train_feature_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestHogRider(model,grid,min_i=4,max_i=10,min_j=1,max_j=2):\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    for i in range(min_i, max_i):\n",
    "        print(i)\n",
    "        for j in range(min_j, max_j):\n",
    "            print(\"--\", j)\n",
    "            train_feature_x = HogRider(i, j)\n",
    "            #faccio grid search\n",
    "            gs = GridSearchCV(model, grid, cv=4, n_jobs=-1)\n",
    "            gs.fit(train_feature_x, train_y)\n",
    "            score = gs.best_score_\n",
    "            \n",
    "            if score > best_score:\n",
    "               best_score = score\n",
    "               best_params = (i, j)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch sui classificatori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'svm__C': 2.4434343434343435, 'svm__degree': 2, 'svm__gamma': 0.0008121212121212122, 'svm__kernel': 'poly'}\n",
      "Score: 0.7688888888888888\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "svm_model = Pipeline([\n",
    "    (\"scaler\", RobustScaler()),\n",
    "    (\"svm\", SVC(random_state=1234))\n",
    "])\n",
    "\n",
    "svm_grid = [\n",
    "    #{\n",
    "    #    'svm__kernel': ['linear'],\n",
    "     #   'svm__C': np.linspace(1, 5, 10) #iperparametro di regolarizzazione\n",
    "    #},\n",
    "    {\n",
    "        'svm__C': [2.4434343434343435], \n",
    "        'svm__gamma': [0.0008121212121212122], #iperparametro del kernel rbf\n",
    "        'svm__kernel': ['poly'],\n",
    "        'svm__degree': [2]}\n",
    "\n",
    "]\n",
    "train_feature_x = HogRider(9,6)\n",
    "svm_gs = GridSearchCV(svm_model, svm_grid, cv=4, n_jobs=-1)\n",
    "svm_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', svm_gs.best_params_)\n",
    "print('Score:', svm_gs.best_score_)\n",
    "if(svm_gs.best_score_ > max):\n",
    "    max = svm_gs.best_score_\n",
    "    print('Migliorato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7277777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Supponiamo che 'HogRider' sia una funzione che genera le caratteristiche\n",
    "# La funzione Ã¨ chiamata per ottenere le caratteristiche di addestramento\n",
    "train_feature_x = HogRider(9, 6)  # Genera le caratteristiche di addestramento\n",
    "\n",
    "# Definizione del GridSearch per ogni SVM\n",
    "svm_grid_rbf = {\n",
    "    'C': [2.4434343434343435],\n",
    "    'gamma': [0.0008121212121212122],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "svm_grid_poly = {\n",
    "    'C': [2.4434343434343435],\n",
    "    'kernel': ['poly'],\n",
    "    'degree': [2]\n",
    "}\n",
    "\n",
    "svm_grid_linear = {\n",
    "    'C': [1.0],\n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Ottimizzazione dei parametri degli SVM con GridSearchCV\n",
    "svm_rbf = GridSearchCV(SVC(probability=True), svm_grid_rbf, cv=4, n_jobs=-1)\n",
    "svm_poly = GridSearchCV(SVC(probability=True), svm_grid_poly, cv=4, n_jobs=-1)\n",
    "svm_linear = GridSearchCV(SVC(probability=True), svm_grid_linear, cv=4, n_jobs=-1)\n",
    "\n",
    "# Addestramento dei modelli base\n",
    "svm_rbf.fit(train_feature_x, train_y)\n",
    "svm_poly.fit(train_feature_x, train_y)\n",
    "svm_linear.fit(train_feature_x, train_y)\n",
    "\n",
    "# Estimatori base ottimizzati con GridSearchCV\n",
    "base_estimators = [\n",
    "    ('svm_rbf', svm_rbf.best_estimator_),\n",
    "    ('svm_poly', svm_poly.best_estimator_),\n",
    "    ('svm_linear', svm_linear.best_estimator_)\n",
    "]\n",
    "\n",
    "# Meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Stacking\n",
    "stacking = StackingClassifier(estimators=base_estimators, final_estimator=meta_model, cv=4, n_jobs=-1)\n",
    "\n",
    "print(cross_val_score(stacking, train_feature_x, train_y, cv=4, n_jobs=-1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "-- 4\n",
      "-- 5\n",
      "-- 6\n",
      "-- 7\n",
      "5\n",
      "-- 4\n",
      "-- 5\n",
      "-- 6\n",
      "-- 7\n",
      "6\n",
      "-- 4\n",
      "-- 5\n",
      "-- 6\n",
      "-- 7\n",
      "7\n",
      "-- 4\n",
      "-- 5\n",
      "-- 6\n",
      "-- 7\n",
      "8\n",
      "-- 4\n",
      "-- 5\n",
      "-- 6\n",
      "-- 7\n",
      "9\n",
      "-- 4\n",
      "-- 5\n",
      "-- 6\n",
      "-- 7\n",
      "10\n",
      "-- 4\n",
      "-- 5\n",
      "-- 6\n",
      "-- 7\n",
      "11\n",
      "-- 4\n",
      "-- 5\n",
      "-- 6\n",
      "-- 7\n",
      "(9, 6)\n"
     ]
    }
   ],
   "source": [
    "print(bestHogRider(svm_model,svm_grid, 4,12,4,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_feature_x)\n",
    "train_feature_x[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'rfc__bootstrap': True, 'rfc__max_depth': 10, 'rfc__max_features': 'sqrt', 'rfc__max_samples': np.float64(0.6), 'rfc__min_samples_leaf': 2, 'rfc__min_samples_split': 2, 'rfc__n_estimators': 1200}\n",
      "Score: 0.7422222222222222\n"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "\n",
    "rfc_model = Pipeline([\n",
    "    (\"rfc\", RandomForestClassifier(random_state=1234))\n",
    "])\n",
    "\n",
    "rfc_grid = {\n",
    "    \"rfc__max_depth\": [10],\n",
    "    \"rfc__max_samples\": np.linspace(0.1, 1, 10),\n",
    "    \"rfc__max_features\": [\"sqrt\"],\n",
    "    'rfc__min_samples_split': [2],\n",
    "    \"rfc__n_estimators\": [1200],\n",
    "    \"rfc__min_samples_leaf\": [2],\n",
    "    'rfc__bootstrap': [True],\n",
    "}\n",
    "\n",
    "rfc_gs = GridSearchCV(rfc_model, rfc_grid, cv=4, n_jobs=-1)\n",
    "rfc_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', rfc_gs.best_params_)\n",
    "print('Score:', rfc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split': [2],\n",
    "    \"rfc__n_estimators\": np.linspace(755-10, 755+00, 10, dtype=int)\n",
    "}\n",
    "train_feature_x = HogRider(9,8)\n",
    "\n",
    "rfc_gs = GridSearchCV(rfc_model, rfc_grid, cv=4, n_jobs=-1)\n",
    "rfc_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', rfc_gs.best_params_)\n",
    "print('Score:', rfc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'max_depth': 7, 'min_samples_split': 5}\n",
      "Score: 0.5888888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_model =  DecisionTreeClassifier(random_state=1234)\n",
    "\n",
    "decision_grid = {\n",
    "     \"max_depth\": [7],\n",
    "     \"min_samples_split\": [5]\n",
    "\n",
    "     }\n",
    "\n",
    "decision_gs = GridSearchCV(decision_model, decision_grid, cv=4, n_jobs=-1)\n",
    "decision_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', decision_gs.best_params_)\n",
    "print('Score:', decision_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'ada__estimator': DecisionTreeClassifier(random_state=1234), 'ada__learning_rate': np.float64(0.0001), 'ada__n_estimators': 1}\n",
      "Score: 0.56\n"
     ]
    }
   ],
   "source": [
    "#Adaboost\n",
    "\n",
    "ada_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ada\", AdaBoostClassifier(random_state=1234))\n",
    "])\n",
    "\n",
    "ada_grid = {\n",
    "    'ada__estimator': [decision_model],\n",
    "    \"ada__n_estimators\": range(1, 10, 1),\n",
    "    \"ada__learning_rate\": np.logspace(-4,-1,4)\n",
    "}\n",
    "\n",
    "ada_gs = GridSearchCV(ada_model, ada_grid, cv=4, n_jobs=-1)\n",
    "ada_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', ada_gs.best_params_)\n",
    "print('Score:', ada_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'xgb__alpha': 0.01, 'xgb__max_depth': 2, 'xgb__n_estimators': 300}\n",
      "Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "\n",
    "xgb_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"xgb\", XGBClassifier(objective='binary:logistic'))\n",
    "])\n",
    "\n",
    "xgb_grid = {\n",
    "    \"xgb__max_depth\": [2, 4, 6, 8, 10],\n",
    "    \"xgb__n_estimators\": [100, 200, 300],\n",
    "    \"xgb__alpha\": [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "xgb_gs = GridSearchCV(xgb_model, xgb_grid, cv=4, n_jobs=-1)\n",
    "xgb_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', xgb_gs.best_params_)\n",
    "print('Score:', xgb_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'linreg__C': 0.8416666666666666, 'linreg__l1_ratio': np.float64(0.18888888888888886), 'linreg__penalty': 'elasticnet', 'linreg__solver': 'saga'}\n",
      "Score: 0.731111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "log_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linreg\", LogisticRegression(random_state=1234))\n",
    "])\n",
    "\n",
    "log_grid = [\n",
    "    \n",
    "    {\n",
    "        \"linreg__penalty\": ['elasticnet'],\n",
    "        \"linreg__solver\": ['saga'],\n",
    "        \"linreg__C\": [0.8416666666666666],\n",
    "        \"linreg__l1_ratio\": np.linspace(0.18888888888888886-0.1, 0.18888888888888886+0.1, 10)\n",
    "    }\n",
    "]\n",
    "\n",
    "log_gs = GridSearchCV(log_model, log_grid, cv=4, n_jobs=-1)\n",
    "log_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', log_gs.best_params_)\n",
    "print('Score:', log_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 2: valutazione su test set\n",
    "\n",
    "# Path contenente i pattern di test\n",
    "image_side = 128\n",
    "db_path = 'DBs/CaniGatti_ML18'\n",
    "exp_path = 'Experiments'\n",
    "train_filelist = 'BinaryTrainingSet.txt' \n",
    "test_filelist = 'Unlabeled_BinaryTestSet.txt'\n",
    "result_path = 'Es4Predictions.txt'\n",
    "memory = Memory(exp_path, verbose=0) \n",
    "\n",
    "# Caricamento dei pattern di training\n",
    "train_raw_x, train_y = ml_utilities.load_labeled_dataset(train_filelist, db_path, cache=memory)\n",
    "train_raw_x = ml_utilities.resize_images(train_raw_x, image_side, image_side, cache=memory)\n",
    "\n",
    "# Preprocessing ed estrazione HOG (training)\n",
    "train_feature_x = ml_utilities.extract_hog(train_raw_x, \n",
    "                                           convert_to_gray=True, orientations=9,\n",
    "                                           pixels_per_cell=(8, 8), cells_per_block=(1, 1),\n",
    "                                           cache=memory)\n",
    "\n",
    "# Creazione del classificatore\n",
    "clf = ... #TODO: trovare il migliore classificatore con i migliori iperparametri\n",
    "\n",
    "# Addestramento del classificatore\n",
    "clf.fit(train_feature_x, train_y)\n",
    "\n",
    "# Caricamento dei pattern di test\n",
    "test_raw_x = ml_utilities.load_unlabeled_dataset(test_filelist, db_path, cache=memory)\n",
    "test_raw_x = ml_utilities.resize_images(test_raw_x, image_side, image_side, cache=memory)\n",
    "\n",
    "# Preprocessing ed estrazione HOG (test)\n",
    "test_feature_x = ml_utilities.extract_hog(test_raw_x, \n",
    "                                           convert_to_gray=True, orientations=9,\n",
    "                                           pixels_per_cell=(8, 8), cells_per_block=(1, 1),\n",
    "                                           cache=memory)\n",
    "\n",
    "# Salvataggio delle predictions\n",
    "predictions = clf.predict(test_feature_x)\n",
    "\n",
    "with open(result_path, \"w\") as f:\n",
    "    for prediction in predictions:\n",
    "        f.write(str(int(prediction)) + '\\n')\n",
    "print('Ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
