{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione 4: classificazione cani e gatti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Memory\n",
    "from skimage import feature, color, transform\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import ml_utilities\n",
    "import ml_visualization\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento in corso ...\n",
      "Caricate 900 immagini in 0.58 s.\n",
      "Gatti: 509\n",
      "Cani: 391\n"
     ]
    }
   ],
   "source": [
    "db_path = 'DBs/CaniGatti_ML18'\n",
    "exp_path = 'Experiments'\n",
    "train_filelist = 'BinaryTrainingSet.txt'  \n",
    "\n",
    "# Predisposizione di un'area di caching su disco che velocizza la riesecuzione di chiamate di funzioni con gli stessi parametri\n",
    "memory = Memory(exp_path, verbose=0)  \n",
    "\n",
    "# Caricamento delle immagini\n",
    "print('Caricamento in corso ...')\n",
    "start = time.time()\n",
    "train_raw_x, train_y = ml_utilities.load_labeled_dataset(train_filelist, db_path, cache=memory)\n",
    "\n",
    "print('Caricate %d immagini in %.2f s.' % (len(train_raw_x), time.time() - start))\n",
    "print('Gatti:', np.count_nonzero(train_y == 0))\n",
    "print('Cani:', np.count_nonzero(train_y == 1))\n",
    "\n",
    "# Shuffle del training set\n",
    "ml_utilities.shuffle_in_unison([train_raw_x, train_y], seed=1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_side = 128\n",
    "train_raw_x = ml_utilities.resize_images(train_raw_x, image_side, image_side, cache=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrazione delle feature HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_x = ml_utilities.extract_hog(train_raw_x, \n",
    "                                           convert_to_gray=True, orientations=11,\n",
    "                                           pixels_per_cell=(8, 8), cells_per_block=(1, 1),\n",
    "                                           cache=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch sui classificatori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'kNN__n_neighbors': 1, 'kNN__weights': 'uniform'}\n",
      "Score: 0.6066666666666667\n"
     ]
    }
   ],
   "source": [
    "#Modello k-NN\n",
    "\n",
    "kNN_model = Pipeline([\n",
    "    (\"scaler\", None),\n",
    "    (\"kNN\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "kNN_grid = {\n",
    "    #'scaler': [None, StandardScaler()],\n",
    "    'kNN__n_neighbors': range(1, 11), #iperparamtro k (numero di vicini da considerare)\n",
    "    'kNN__weights': ['uniform', 'distance'], #uniform: tutti i punti vicini hanno lo stesso peso. distance: più i punti sono vicini più saranno influenti\n",
    "}\n",
    "\n",
    "kNN_gs = GridSearchCV(kNN_model, kNN_grid, cv=5, n_jobs=-1)\n",
    "kNN_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', kNN_gs.best_params_)\n",
    "print('Score:', kNN_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'C': 1.7486709197235513, 'decision_function_shape': 'ovr', 'gamma': 0.00034625005324914943, 'kernel': 'rbf'}\n",
      "Score: 0.5655555555555555\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "svm_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(random_state=1234))\n",
    "])\n",
    "\n",
    "svm_grid = [\n",
    "    #{\n",
    "    #    'svm__kernel': ['linear'],\n",
    "     #   'svm__C': np.linspace(1, 5, 10) #iperparametro di regolarizzazione\n",
    "    #},\n",
    "    {\n",
    "        'svm__C': [1.7486709197235513], \n",
    "        'svm__gamma': [0.00034625005324914943], \n",
    "        'svm__kernel': ['rbf'],\n",
    "        'svm__decision_function_shape': [ 'ovr']}\n",
    "        #'svm__C': [3.7272727272727275], #iperparametro di regolarizzazione\n",
    "        #'svm__gamma': [7.900000000000001e-05], #coefficiente del kernel rbf\n",
    "\n",
    "]\n",
    "train_feature_x = HogRider(9,8)\n",
    "svm_gs = GridSearchCV(svm_model, svm_grid, cv=4, n_jobs=-1)\n",
    "svm_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', svm_gs.best_params_)\n",
    "print('Score:', svm_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "-- 5\n",
      "-- 6\n",
      "-- 7\n",
      "-- 8\n",
      "-- 9\n",
      "(9, 8)\n"
     ]
    }
   ],
   "source": [
    "print(bestHogRider(svm_model,svm_grid, 9,10,5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_feature_x)\n",
    "train_feature_x[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'rfc__bootstrap': True, 'rfc__max_depth': 10, 'rfc__max_features': 'sqrt', 'rfc__max_samples': np.float64(0.6), 'rfc__min_samples_leaf': 2, 'rfc__min_samples_split': 2, 'rfc__n_estimators': 1200}\n",
      "Score: 0.7422222222222222\n"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "\n",
    "rfc_model = Pipeline([\n",
    "    (\"rfc\", RandomForestClassifier(random_state=1234))\n",
    "])\n",
    "\n",
    "rfc_grid = {\n",
    "    \"rfc__max_depth\": [10],\n",
    "    \"rfc__max_samples\": np.linspace(0.1, 1, 10),\n",
    "    \"rfc__max_features\": [\"sqrt\"],\n",
    "    'rfc__min_samples_split': [2],\n",
    "    \"rfc__n_estimators\": [1200],\n",
    "    \"rfc__min_samples_leaf\": [2],\n",
    "    'rfc__bootstrap': [True],\n",
    "}\n",
    "\n",
    "rfc_gs = GridSearchCV(rfc_model, rfc_grid, cv=4, n_jobs=-1)\n",
    "rfc_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', rfc_gs.best_params_)\n",
    "print('Score:', rfc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split': [2],\n",
    "    \"rfc__n_estimators\": np.linspace(755-10, 755+00, 10, dtype=int)\n",
    "}\n",
    "train_feature_x = HogRider(9,8)\n",
    "\n",
    "rfc_gs = GridSearchCV(rfc_model, rfc_grid, cv=4, n_jobs=-1)\n",
    "rfc_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', rfc_gs.best_params_)\n",
    "print('Score:', rfc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'max_depth': 7, 'min_samples_split': 5}\n",
      "Score: 0.5888888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_model =  DecisionTreeClassifier(random_state=1234)\n",
    "\n",
    "decision_grid = {\n",
    "     \"max_depth\": [7],\n",
    "     \"min_samples_split\": [5]\n",
    "\n",
    "     }\n",
    "\n",
    "decision_gs = GridSearchCV(decision_model, decision_grid, cv=4, n_jobs=-1)\n",
    "decision_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', decision_gs.best_params_)\n",
    "print('Score:', decision_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'ada__estimator': DecisionTreeClassifier(random_state=1234), 'ada__learning_rate': np.float64(0.0001), 'ada__n_estimators': 1}\n",
      "Score: 0.56\n"
     ]
    }
   ],
   "source": [
    "#Adaboost\n",
    "\n",
    "ada_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ada\", AdaBoostClassifier(random_state=1234))\n",
    "])\n",
    "\n",
    "ada_grid = {\n",
    "    'ada__estimator': [decision_model],\n",
    "    \"ada__n_estimators\": range(1, 10, 1),\n",
    "    \"ada__learning_rate\": np.logspace(-4,-1,4)\n",
    "}\n",
    "\n",
    "ada_gs = GridSearchCV(ada_model, ada_grid, cv=4, n_jobs=-1)\n",
    "ada_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', ada_gs.best_params_)\n",
    "print('Score:', ada_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'xgb__alpha': 0.01, 'xgb__max_depth': 2, 'xgb__n_estimators': 300}\n",
      "Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "\n",
    "xgb_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"xgb\", XGBClassifier(objective='binary:logistic'))\n",
    "])\n",
    "\n",
    "xgb_grid = {\n",
    "    \"xgb__max_depth\": [2, 4, 6, 8, 10],\n",
    "    \"xgb__n_estimators\": [100, 200, 300],\n",
    "    \"xgb__alpha\": [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "xgb_gs = GridSearchCV(xgb_model, xgb_grid, cv=4, n_jobs=-1)\n",
    "xgb_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', xgb_gs.best_params_)\n",
    "print('Score:', xgb_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri scelti: {'linreg__C': 0.8416666666666666, 'linreg__l1_ratio': np.float64(0.18888888888888886), 'linreg__penalty': 'elasticnet', 'linreg__solver': 'saga'}\n",
      "Score: 0.731111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "log_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linreg\", LogisticRegression(random_state=1234))\n",
    "])\n",
    "\n",
    "log_grid = [\n",
    "    \n",
    "    {\n",
    "        \"linreg__penalty\": ['elasticnet'],\n",
    "        \"linreg__solver\": ['saga'],\n",
    "        \"linreg__C\": [0.8416666666666666],\n",
    "        \"linreg__l1_ratio\": np.linspace(0.18888888888888886-0.1, 0.18888888888888886+0.1, 10)\n",
    "    }\n",
    "]\n",
    "\n",
    "log_gs = GridSearchCV(log_model, log_grid, cv=4, n_jobs=-1)\n",
    "log_gs.fit(train_feature_x, train_y)\n",
    "\n",
    "print('Parametri scelti:', log_gs.best_params_)\n",
    "print('Score:', log_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 2: valutazione su test set\n",
    "\n",
    "# Path contenente i pattern di test\n",
    "image_side = 128\n",
    "db_path = 'DBs/CaniGatti_ML18'\n",
    "exp_path = 'Experiments'\n",
    "train_filelist = 'BinaryTrainingSet.txt' \n",
    "test_filelist = 'Unlabeled_BinaryTestSet.txt'\n",
    "result_path = 'Es4Predictions.txt'\n",
    "memory = Memory(exp_path, verbose=0) \n",
    "\n",
    "# Caricamento dei pattern di training\n",
    "train_raw_x, train_y = ml_utilities.load_labeled_dataset(train_filelist, db_path, cache=memory)\n",
    "train_raw_x = ml_utilities.resize_images(train_raw_x, image_side, image_side, cache=memory)\n",
    "\n",
    "# Preprocessing ed estrazione HOG (training)\n",
    "train_feature_x = ml_utilities.extract_hog(train_raw_x, \n",
    "                                           convert_to_gray=True, orientations=9,\n",
    "                                           pixels_per_cell=(8, 8), cells_per_block=(1, 1),\n",
    "                                           cache=memory)\n",
    "\n",
    "# Creazione del classificatore\n",
    "clf = ... #TODO: trovare il migliore classificatore con i migliori iperparametri\n",
    "\n",
    "# Addestramento del classificatore\n",
    "clf.fit(train_feature_x, train_y)\n",
    "\n",
    "# Caricamento dei pattern di test\n",
    "test_raw_x = ml_utilities.load_unlabeled_dataset(test_filelist, db_path, cache=memory)\n",
    "test_raw_x = ml_utilities.resize_images(test_raw_x, image_side, image_side, cache=memory)\n",
    "\n",
    "# Preprocessing ed estrazione HOG (test)\n",
    "test_feature_x = ml_utilities.extract_hog(test_raw_x, \n",
    "                                           convert_to_gray=True, orientations=9,\n",
    "                                           pixels_per_cell=(8, 8), cells_per_block=(1, 1),\n",
    "                                           cache=memory)\n",
    "\n",
    "# Salvataggio delle predictions\n",
    "predictions = clf.predict(test_feature_x)\n",
    "\n",
    "with open(result_path, \"w\") as f:\n",
    "    for prediction in predictions:\n",
    "        f.write(str(int(prediction)) + '\\n')\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestHogRider(model,grid,min_i=4,max_i=10,min_j=1,max_j=2):\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    for i in range(min_i, max_i):\n",
    "        print(i)\n",
    "        for j in range(min_j, max_j):\n",
    "            print(\"--\", j)\n",
    "            train_feature_x = HogRider(i, j)\n",
    "            #faccio grid search\n",
    "            gs = GridSearchCV(model, grid, cv=4, n_jobs=-1)\n",
    "            gs.fit(train_feature_x, train_y)\n",
    "            score = gs.best_score_\n",
    "            \n",
    "            if score > best_score:\n",
    "               best_score = score\n",
    "               best_params = (i, j)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HogRider(orientation,side):\n",
    "     train_feature_x = ml_utilities.extract_hog(train_raw_x, \n",
    "                                           convert_to_gray=True, orientations=orientation,\n",
    "                                           pixels_per_cell=(side,side), cells_per_block=(1, 1),\n",
    "                                           cache=memory)\n",
    "     return train_feature_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
